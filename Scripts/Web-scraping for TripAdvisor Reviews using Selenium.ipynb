{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8880dd24",
   "metadata": {},
   "source": [
    "# Scraping TripAdvisor Reviews using Selenium "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683680c3",
   "metadata": {},
   "source": [
    "In this project, we will be scraping the reviews from hotel guests on TripAdvisor for Row NYC Hotel in New York City. There are a total of 9040 reviews and the date of review, review title, review as well as ratings will be extracted from the webpage. \n",
    "This is done through the use of Selenium for web scraping. \n",
    "\n",
    "The flow of this project would be:\n",
    "1. Import relevant libraries \n",
    "2. Extract the individual elements through Selenium \n",
    "3. Build web scraper to automate the scraping of 9040 reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b1b57",
   "metadata": {},
   "source": [
    "## 1. Import relevant libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff808d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from datetime import datetime, timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b34555",
   "metadata": {},
   "source": [
    "## Function to scrape review from tripadvisor.com.sg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6fe96307",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function to scrape reviews\n",
    "\n",
    "def get_reviews(hotel_url, pages = None, based_date = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    1. To scrape all reviews:\n",
    "        - leave pages and based_date as None\n",
    "\n",
    "    2. To scrape recent reviews: \n",
    "        - input page and based_date for shorter run time. (If pages left as None, run time will be long)\n",
    "        - based_date must be in \"mmm yyyy\" format. Eg: 'Jan 2022'\n",
    "    \n",
    "    Output will be a df with the hotel name, date of review, Title of Review, Review, Ratings\n",
    "    \"\"\"\n",
    "    #Create empty list for to append scrape data\n",
    "    hotel_name = [] \n",
    "    Title = []\n",
    "    Date = []\n",
    "    Review = []\n",
    "    ratings = []\n",
    "\n",
    "    #Create empty df\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    if based_date is not None:\n",
    "         based_date_dt = datetime.strptime(based_date, \"%b %Y\").date()\n",
    "    else:\n",
    "         pass\n",
    "\n",
    "    #initiate chrome driver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--incognito')\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "    \n",
    "\n",
    "    #open hotel url page\n",
    "    for url in hotel_url:\n",
    "        driver.get(url)\n",
    "    \n",
    "        #Calculate the ttl pages to scrape for each hotel base on comments for each page (ard 5)\n",
    "        en_rev_ttl = int(driver.find_elements(By.XPATH, \"//span[@class='cvxmR']\")[0].text.replace('(','').replace(')','').replace(',',''))\n",
    "        en_rev_per_pg = len(driver.find_elements(By.XPATH,\"//q[@class = 'XllAv H4 _a']\"))\n",
    "        if pages is None:\n",
    "            pages_to_scrape = int(en_rev_ttl/en_rev_per_pg)\n",
    "        else:\n",
    "            pages_to_scrape = pages + 1\n",
    "                \n",
    "        print(f\"No of pages to scrape is {pages}.\")\n",
    "\n",
    "        #Loop through the pages to scrape     \n",
    "        for page in range(1, pages_to_scrape):\n",
    "                print(f\"page {page}\")\n",
    "                time.sleep(5)\n",
    "                # Click on'Read More' button to expand each review to get full review\n",
    "                element_list = driver.find_elements(By.XPATH, '//span[(@class =\"fmBIl _S Nc\")]') \n",
    "                \n",
    "                if len(element_list) > 0:\n",
    "                    print(f'there is an element: {element_list}')\n",
    "                    driver.execute_script(\"arguments[0].click();\", element_list[0])\n",
    "                else:\n",
    "                    print('theres no element')\n",
    "                time.sleep(2)    \n",
    "                    \n",
    "                # To get the reviews and tag the name of hotel to review\n",
    "                reviews = driver.find_elements(By.XPATH,\"//q[@class = 'XllAv H4 _a']\")\n",
    "                h_name = driver.find_elements(By.XPATH, \"//h1[@class='fkWsC b d Pn']\")\n",
    "                for i in range(len(reviews)):\n",
    "                    Review.append(reviews[i].text)\n",
    "                    hotel_name.append(h_name[0].text)\n",
    "                \n",
    "                \n",
    "                #To get review title\n",
    "                title = driver.find_elements(By.XPATH,\"//div[contains(@data-test-target, 'review-title')]\")\n",
    "                for j in range(len(title)):\n",
    "                    Title.append(title[j].text)\n",
    "        \n",
    "                # To get the dates \n",
    "                # dates = driver.find_elements(By.XPATH,\"//span[@class = 'euPKI _R Me S4 H3']\" )\n",
    "                dates = driver.find_elements(By.XPATH,\"//div[@class = 'bcaHz']\")\n",
    "                \n",
    "                for k in range(len(dates)):\n",
    "                    Date.append(dates[k].text)\n",
    "            \n",
    "                # To get ratings \n",
    "                for div in driver.find_elements(By.XPATH,\"//div[@class = 'emWez F1']\"):\n",
    "                    elements = div.find_elements_by_tag_name('span')\n",
    "                    for i in range(len(elements)):\n",
    "                        ratings.append(elements[i].get_attribute('class'))\n",
    "                    \n",
    "                # Looping through mutiple pages\n",
    "                # XPath diff for .com and .com.sg.        \n",
    "                driver.implicitly_wait(10)\n",
    "                components = ['13', '14', '15']\n",
    "                for comp in components:\n",
    "                    try:\n",
    "                        if page <4:\n",
    "                            \n",
    "                            driver.find_elements (By.XPATH,f'//*//*[@id=\"component_{comp}\"]/div/div[3]/div[8]/div/a[{page}]')[0].click()\n",
    "                        else:\n",
    "                            driver.implicitly_wait(10)  \n",
    "                            driver.find_elements (By.XPATH,f'//*//*[@id=\"component_{comp}\"]/div/div[3]/div[8]/div/a[4]')[0].click()\n",
    "                            time.sleep(3)\n",
    "                    except:\n",
    "                        pass\n",
    "    \n",
    "    zipped = list(zip(hotel_name, Date, Title, Review, ratings))\n",
    "    \n",
    "    #Recreate empty list to append filtered data for use in forming df\n",
    "    hotel_name = [] \n",
    "    Title = []\n",
    "    Date = []\n",
    "    Review = []\n",
    "    ratings = []\n",
    "    \n",
    "    for z in zipped:\n",
    "        # To convert date from str to datetime to compare with based_date\n",
    "        try:\n",
    "            datetime_k = datetime.strptime(z[1][-8:], \"%b %Y\").date()\n",
    "        except:\n",
    "            try:\n",
    "                datetime_k = datetime.strptime(\"Sep\"+\" \"+z[1][-4:], \"%b %Y\").date()\n",
    "            except:\n",
    "                datetime_k = datetime.strptime(z[1][-3:] + \" \" +'2022', \"%b %Y\").date()\n",
    "        \n",
    "        # To filter out reviews that are earlier than based_date\n",
    "        if based_date is not None:\n",
    "            if datetime_k >= based_date_dt:\n",
    "                Date.append(datetime_k)\n",
    "                hotel_name.append(z[0])\n",
    "                Title.append(z[2])\n",
    "                Review.append(z[3])\n",
    "                ratings.append(z[4])\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            Date.append(datetime_k)\n",
    "            hotel_name.append(z[0])\n",
    "            Title.append(z[2])\n",
    "            Review.append(z[3])\n",
    "            ratings.append(z[4])\n",
    "    \n",
    "    # add to df and process for readability\n",
    "    df['Hotel_Name'] = hotel_name\n",
    "    df['Date'] =  Date\n",
    "    df['Title'] = Title\n",
    "    df['Review']= Review\n",
    "    df['Rating']= ratings\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Date'] = df['Date'].dt.to_period('M')\n",
    "    df['Rating'] = df['Rating'].str.replace('ui_bubble_rating bubble_', '')\n",
    "    df['Rating'] = df['Rating'].str.replace('0', '')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4c51a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome with the command:  powershell \"$ErrorActionPreference='silentlycontinue' ; (Get-Item -Path \"$env:PROGRAMFILES\\Google\\Chrome\\Application\\chrome.exe\").VersionInfo.FileVersion ; if (-not $? -or $? -match $error) { (Get-Item -Path \"$env:PROGRAMFILES(x86)\\Google\\Chrome\\Application\\chrome.exe\").VersionInfo.FileVersion } if (-not $? -or $? -match $error) { (Get-Item -Path \"$env:LOCALAPPDATA\\Google\\Chrome\\Application\\chrome.exe\").VersionInfo.FileVersion } if (-not $? -or $? -match $error) { reg query \"HKCU\\SOFTWARE\\Google\\Chrome\\BLBeacon\" /v version } if (-not $? -or $? -match $error) { reg query \"HKLM\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\Google Chrome\" /v version }\"\n",
      "Current google-chrome version is UNKNOWN\n",
      "Get LATEST chromedriver version for UNKNOWN google-chrome\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/101.0.4951.41/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\edowi\\.wdm\\drivers\\chromedriver\\win32\\101.0.4951.41]\n",
      "C:\\Users\\edowi\\AppData\\Local\\Temp\\ipykernel_10936\\3784660469.py:23: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of pages to scrape is 2.\n",
      "page 1\n",
      "there is an element: [<selenium.webdriver.remote.webelement.WebElement (session=\"59e20d274eb0ebff771fcbbf516b5076\", element=\"a358a18d-4447-4e83-8c0c-c3fbb1bfe48c\")>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edowi\\anaconda3\\envs\\mages\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:359: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 2\n",
      "there is an element: [<selenium.webdriver.remote.webelement.WebElement (session=\"59e20d274eb0ebff771fcbbf516b5076\", element=\"739ba5df-a01b-4521-bcfb-b8d106da1b3a\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"59e20d274eb0ebff771fcbbf516b5076\", element=\"0e6cfb9f-7b3b-4ae8-9d20-f4c56fd233d9\")>]\n",
      "No of pages to scrape is 2.\n",
      "page 1\n",
      "there is an element: [<selenium.webdriver.remote.webelement.WebElement (session=\"59e20d274eb0ebff771fcbbf516b5076\", element=\"4b1d0460-423e-49af-b61d-95c4050930ee\")>]\n",
      "page 2\n",
      "there is an element: [<selenium.webdriver.remote.webelement.WebElement (session=\"59e20d274eb0ebff771fcbbf516b5076\", element=\"ae48d3eb-4d95-4e71-bc14-21ef893b5c12\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"59e20d274eb0ebff771fcbbf516b5076\", element=\"86d4da84-fa74-4340-912f-de28763aa22b\")>]\n",
      "['cjclay5 wrote a review 6 May', 'Joyce K wrote a review Apr 2022', 'rammkhamkaew wrote a review Apr 2022', 'Ben Chua wrote a review Dec 2021', '253SA wrote a review Dec 2021', 'mike_traveller20xx wrote a review Nov 2021', 'Hyrul wrote a review Jul 2021', 'Edward T wrote a review Mar 2021', 'Janemarie L wrote a review Mar 2021', 'Sy T wrote a review Jan 2021', 'Emma B wrote a review Feb 2022', 'mike_traveller20xx wrote a review Nov 2021', 'Loh Foong Heng wrote a review Mar 2021', 'Loh Y wrote a review Feb 2021', 'Jackie E wrote a review Mar 2020', 'Leigh M wrote a review Dec 2019', 'Wallflower wrote a review Oct 2019', 'gaby_pa wrote a review Sept 2019', 'AdrianH4 wrote a review Sept 2019', 'Troy Agung wrote a review Aug 2019']\n"
     ]
    }
   ],
   "source": [
    "# Set up list of hotel url to scrape\n",
    "# ['https://www.tripadvisor.com.sg/Hotel_Review-g294265-d568053-Reviews-Ibis_budget_Singapore_Emerald-Singapore.html']\n",
    "# ['https://www.tripadvisor.com.sg/Hotel_Review-g294265-d506320-Reviews-Ibis_budget_Singapore_Joo_Chiat-Singapore.html']\n",
    "#['https://www.tripadvisor.com.sg/Hotel_Review-g294265-d1089215-Reviews-Ibis_budget_Singapore_West_Coast-Singapore.html']\n",
    "# ['https://www.tripadvisor.com.sg/Hotel_Review-g294265-d1008216-Reviews-Ibis_Budget_Singapore_Ametrine-Singapore.html']\n",
    "# ['https://www.tripadvisor.com.sg/Hotel_Review-g294265-d1015609-Reviews-Ibis_budget_Singapore_Imperial-Singapore.html']\n",
    "# 'https://www.tripadvisor.com.sg/Hotel_Review-g294265-d2439500-Reviews-Ibis_Budget_Singapore_Clarke_Quay-Singapore.html',\n",
    "hotel_url = ['https://www.tripadvisor.com.sg/Hotel_Review-g294265-d2439500-Reviews-Ibis_Budget_Singapore_Clarke_Quay-Singapore.html',\n",
    "             'https://www.tripadvisor.com.sg/Hotel_Review-g294265-d1823538-Reviews-Ibis_budget_Singapore_Bugis-Singapore.html']\n",
    "\n",
    "#run function to capture data and save into variable data\n",
    "# based_date format: \"mmm yyyy\" eg: 'Jan 2022'\n",
    "df_rev = get_reviews(hotel_url, pages = 2, based_date = 'Jan 2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a018a1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ibis Budget Singapore Clarke Quay</td>\n",
       "      <td>2022-05</td>\n",
       "      <td>A comfortable stay</td>\n",
       "      <td>The Ibis Budget in Clarke Quay is the perfect ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ibis Budget Singapore Clarke Quay</td>\n",
       "      <td>2022-04</td>\n",
       "      <td>Gd location and Comfortable rooms</td>\n",
       "      <td>Had a 3D 2N staycation in a superior twin bed ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ibis Budget Singapore Clarke Quay</td>\n",
       "      <td>2022-04</td>\n",
       "      <td>Ibis budget Clarke quay</td>\n",
       "      <td>Good place, good location, close to mrt statio...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ibis budget Singapore Bugis</td>\n",
       "      <td>2022-02</td>\n",
       "      <td>Great value and location</td>\n",
       "      <td>No frills hotel but excellent location with ve...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Hotel_Name     Date  \\\n",
       "0  Ibis Budget Singapore Clarke Quay  2022-05   \n",
       "1  Ibis Budget Singapore Clarke Quay  2022-04   \n",
       "2  Ibis Budget Singapore Clarke Quay  2022-04   \n",
       "3        ibis budget Singapore Bugis  2022-02   \n",
       "\n",
       "                               Title  \\\n",
       "0                 A comfortable stay   \n",
       "1  Gd location and Comfortable rooms   \n",
       "2            Ibis budget Clarke quay   \n",
       "3           Great value and location   \n",
       "\n",
       "                                              Review Rating  \n",
       "0  The Ibis Budget in Clarke Quay is the perfect ...      5  \n",
       "1  Had a 3D 2N staycation in a superior twin bed ...      4  \n",
       "2  Good place, good location, close to mrt statio...      4  \n",
       "3  No frills hotel but excellent location with ve...      4  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "adee2097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype    \n",
      "---  ------      --------------  -----    \n",
      " 0   Hotel_Name  4 non-null      object   \n",
      " 1   Date        4 non-null      period[M]\n",
      " 2   Title       4 non-null      object   \n",
      " 3   Review      4 non-null      object   \n",
      " 4   Rating      4 non-null      object   \n",
      "dtypes: object(4), period[M](1)\n",
      "memory usage: 288.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_rev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "631a3487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df as CSV for future NLP analysis \n",
    "df_rev.to_csv('ibis_budget_recent_rev.csv', encoding = 'utf8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d401544c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ea8361deffccb018a664ee69e8467e531a490538e73920272fb7addf31f36d6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mages')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
